{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAIAAACyr5FlAAAfGElEQVR4Ae1dT0gbW9s/iovgRqiz0SyE4CK4ueO3GLpJLuUGBOH9IIELvgGhxEVXWcSuAu0ifHfhprNwMZvyBWrpZiALDaLo2GK0eOcVi8gb7ggDtS2JYORDKcFCF/Ohv77PPXfy51obJxrPEMLJmTPPOed5fuf5d84oc8QlONCAA6xBvagWHHAEOAQIGnLAO3BUxNUKDlSr1YbCbPUN78ARDAZ94vphDuRyuVZjoCE978AhSRIT1w9zQNf1hsJs9Q3vwBEIBH6YM4IA60zNIcDREmgLcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JRICjM+XaklkJcLSEjZ1JpPPB4fP5Qn93KYoC8UqS1Lwt/xauoijBYLA5Lr6LIEgFg8HaMciy7OrI7/fXNqs7nkAgEAqFXI+7foZCIX5quNv54Mhms5d56TcSiTDGDMNo3tiyLDAuEomgZS1Peb7/7bvIRJAx5vP5msiDEMwY0zSt0TgLhYLrbdBSqeQ4Tjab5QfGlzHrQqHAVzJ2B96VTafT/N+qoL85wVeWy2UsTcuywHT+Ll8mFsfjcbR0ScLFX0IbT4QvE0HGWKFQIJHzbSqVSqlUIq2gqmrdZvzUfD4fRtLT00P1sVjMNTzGWDqdBjUepmjWBKk0gFYV2vmWfc/FxRhLJBKYD3hN9WAHxJPL5RhjuOX6JubGYjHQ8fv9VFlbAH8Nw/hbgoqigKBhGIFAoFG/Pp8PzUzTBC5pCpIkkZpMJBIYTE9PDzQHnnLpuWAwiHrHcUzTdI3/roCDpk0r3sUmNAA4dF2n9o0KVwBHI1Kop4E1V0WyLEOcddUAYwx6Ip1Og6wLHC7bweNGgONPzVFXBrzmaC7LloODCNYdGA2G1jqcJKonKAAcqVSKaoAAXdfL5bLjOHQLasayLGgIAY5LgYP3A1zcp58ky8uYFdgperZugQiSb1G3GYGjrubw+XyNwBEKhchy+Xw+ohMIBFKplDAr59wmn6PuAoXmsG1bq7my2WwmkyFHj2R5GXCUSqUaelojgtcEjmQySeGYZVlQJ6qqMsagQoTmuBQ4yEerLZDkvgsctXSohgJUIkhdtFZzwAsh1eI4DoUniLcFOC4FDtu2s/WuH9Ec9ejVV0XXCg7GGGVoSHcKcHxbh5cxKx3pc1D8whhz5XYFOL4DHN/lP17G50Ceo66ZoEoyK7Sg6RZfIEeybrRCoSyFJBTK8uDgCTLGBDi+MeQymuO78hw9PT0uXvM/+SQYX19bvmSeg8DRKFqBN0NQEOAg9+5bocniuww4DMPwN7hqoxVFUeq2hfgBjkKhULeN3++nXBxltwqFgizLte1BkDKklmW5ug4Gg5TTjMfjaC/A8R3gQEzvOE5dv4/2VtwUud+IL8gKcHf+UoT6ob2Vv9z76w8KWEi0f73/7RfCTsZYJpOp24AqbdsmfUZ7K5lMplZdoQaDtG3b1aD5eKi7lhTaubdC04avXq1WacnSLbK+zWeL7W+yAo0aw89osn1KD/L76dlslvbJqAEKmqbRUDOZTKVScTXAT8MwXFMD4mm3hYhQATt5tZ7WnQMHYwxKm1jDF3p6epTGVygUIoOFgxqN2ypYu5cnSMNoRJkaoODz+Vy9h0Khut6xJEm1x0Fc1BTl24D5+rsIDn7+otyEAwIcTZhz128JcNwgBKRSKV3XVVXN/OfStPMtmLpRqwfjFuDwgMmX7QLCSCQSgYsrGAzGYjGEErquUxR9WXJcu1AolMvlmvikXNs/iwIcf/Ki7SXsjlJkS+OBkCh1QfWXL+As4GUStTxNAQ6eG20uAxx8ZIsBQbR8oiIQCNQNTJpMgOIsvo3f769bjzYCHDyv2lxuBA7sfYRCIZ/PB48kEonEYjFN03hLEYlE4KsgylVVNZvN+v1+n88Xj8eTySTvu4RCIdTEYjHQrDVbAhxtBgTfPcDhSt0iH4p8azKZdByH7A4ScTjFwxiTJAmHlTRNUxQF6T6gB2U6QJpIJLLZLOkM3K3dyRPg4KXT5rKmadVqNZPJxOPxRCKhqqphGKVSiQyKpmmURMdYLcsikdP7LNQ+l8uhHAgEqtUqbShalkVtQEfXdQIZcUGAg1jR/oKmaZVKRVXVdDoNAxGPx3ltH4lE+NS4oigucED3kA6IxWLQHMFgkAcHmqmqClMFrePSWHfipab2y/zSI6hrVlxPw4FIJBLxi8uyLD4GcYGDnnWBw+fzwY9xHAcHZuu6t0JzEAPbX4Boa6MVGlk6nTZNM5VK0autpmnyZuWS4ABBRVHS6TTtG/O+LRoIcBDn219oDg6cRKFTPHi3trlZoSm5NEcymSRvlDEWDAbh3NBGvwAHse6mFJqDA7v//P4qohV+qx1tyOegicEhpbOxuVzO5X4GAgHLsgQ4iGM3rgANz2cj+CGGQiHHcXK5HP5HfSQSAZhs24aXKkkSKCQSCd6N7enpQbBqmiZa4tQIKQ9ZljVNq83ACrPC87/N5Xg8rqpqbdRAw1IUBdFpIpGIRCJ+vz+VSqXTabgpsiwnk8l0Oh2PxykXgkgkHo+n0+lUKoV6v9+fvrgSF1cqlapVNiJaIbbfpoIkSbxi+JGh46RqIwpCczTijKi/A3+8RQj5yhwQmuPKrOv8BwU4Ol/GV56hAMeVWdf5DwpwdL6MrzxDAY4rs67zHxTg6HwZX3mGAhxXZl3nPyjA0fkyvvIMOxMc/HGpK7NGPEgHguq+sd3aSu/eslcURRLXD3OgMzVHVVyt4EBrdUNzat5pjubjEHdvIAcEOG6gUG7KkAQ4bookbuA4vAPHl/LR2afDL+WjK3/OPh1+Pfl8eSZWq9WvJ59rH/lSPkJ97V2+vrb8t13zlDHNRo+AFa67X08+nx2UvpSP+PpqtUpkXbf4ZtdR9g4cm8NjOmOLbID/LLGh2g/fgC/rjG2HJ+tyoe7f7DrdKa50jSyxIXrqS/loc3hsrXd0fTC8Phhe6RrZkqM8we3w5ErXyFrv6BIbWusdfXPvPlousaH96Rm0fD/z/EDLEua+lI+Olzf2p2e25Ci1x1NrvaNvlfHTnSLfheM4X08+bw6PLbC+g//5X9et7fDkAuujvr6efN6SoytdI+uD4Tf37q/1jtZSc1Fo4U/vwLEbTf7+4Nfi1JP96Zni1JO9ice70eS78Ufb4cktObodnsTn3fij3Whyb+IxWu5Pz9DH/GXCfjpbd/L70zPG8H9BYCdbu7//49ej+denO8UF1rfEhhZY3/HyhuM4H2df6oytdo+sdJ1/FtnAWu8oLcevJ5/XekcXWN+WHC1OPdmSo0DJIhvQGXs3/ghd209ndcbWeke35OiWHCX4Ak9LbAj08b3A+la7R84Ozv9pF38dL2/kWb/OWHlunuoBGn4NnB2UsHiA8kU2cLK1S+2vu+AdOK51Jl/KR0tsaHN47EDLvht/9Ef6t0U2sD4YxrLTGStOPTl/k+zpbJ71r/WOrnSNvLl3HyuSdMDH2ZeQ5XZ4sjw3f7y8UZ6b//DsxYdnL97PPAe8HMc5mn+tM7Y+GC7PzR/Nv7afzgIWBekBAIGfWOsF6YHO2BIbqhUqQMarLtSsdI2cfToEu062dhfZwJt796E2VrtHOlNz2E9nf3/w6+bwGFQuvjeHx7bDk7vRJD6kSNZ6R1e7R1a7z43CWu/o5vDY+YM//fx+5nktyGjpF6ee6IxtydH96Zm9h9Nnnw73p2eW2NCbe/c3h8cADoj/zb37eda/xIZINtVqdX0wvMD6IOMF1gfdAH32Vhn/OPsSXZ8dlHTGPjx7QSMpz80vsgFQO90pvp95ThJd7T63XHsPp4+XN+ynszv/nDqaf40H9yYeoxeCAmre3LvPt8mz/s4HB3wOiBzfK13fxL/EhqCcyf8AaKDe340/WmQDq90jvG4Hf+FDQA3sTTzGsoa6PnyVP9nahUGxn84usoHTneKWHIVczw5KwA2B4+ygBGgusoHi1JPTneL6YBjj2Rwee6uM87h8c+8++TGO45wdlDA8Eur+9AzBhTCE3hfZAOzRave59lpiQ6ST3o0/wmJAm91oEn5P54NjOzyJRYypNvrOs35ao2Dr6U4RzkGe9cM6ELsPX+V1xmCPF1gfTDsEs9Y7SmDam3gM8K10jZD8HMfZHB4jT+Jo/vW/p9P70zNY6+9nnsP6rHSNFKee/JH+7fBVnvrdDk/qjBGpLTkKfJMjWZ6bh4qCxsKDm8NjBAhixSIbIDrUAKCB+oF56nCzsj4YhvXFcuRVCMwH6uGO8R5ceW4eYQ7vqYHdR/OvweUlNrQ+GEbMcjT/Go7FIhsgqeiMbQ6PkQFyHOf9zHPeH9yfngGYAGJA5M29+wXpwRIb0hmDZgLBL+Wj9Z9+hlo6Xt7AcgeY4KBA68CfhQcDsiRpWhuLbACw+1I+ghtEt1wFmNrO9DlOtnY/zr7cjSahVHnnY3N4jAIWhCpH86/56PT/tv51srV7vLzhYg2iDwiPlEpx6gk0zVrv6PHyxuGrfJ71v1XGIVdEku/GH32LI/7j+r2feQ7N9G78Edb32UEJTsC5e/TTz6QVzu3Ip0PEKYhNKOhd6x2Fisqz/vXBMOkemJhaZLy5d5/Acfbp8O6C4+yg9H9b/yIJQUi1aShq8PXk8+lOESHD4at8eW7+QMu6fP7j5Y31n35eHwzvRpMAE8w/meolNpRn/XnWT6r77KAEx3ORDfB+AwIZ5M02h8dwd30wDFSdHZQIfI7jbMnRBdYH8UOiwATWOpIiZ58Ozw5KZCkQPLuUAcCBsZ0dlO4uOOCQbg6P8caboACsnO4UD1/l96dndqNJJKlIunAzef9x7+H0gZblLYXjOIev8gusD8koaPWVrpEF1kcqB+ajID1YYH28j/l+5vkC6ytOPdmNJiFCGLvt8CTiLB4cxakn6AXOwbvxR4ev8h+evQBc8qyfuoO7Qx7GWu9oQXqw0jWCWAmPC3A4MLoQNsIQZLeQENsOT9ISzLN+hCekACCtRTawGz3/62xIZ8EKbMlRyAb1EAbctyU2VJ6bPzsorfWOmr9MoMHpTtH8ZQLmgAfWh2cvIDA4EOgRwkYSjDcrgCBSKQusjxJZIEvxDtzbJTa0G02eHZQoY7s5PGY/nUVsQtHKndYcfLQC3x4KH1BYYkPIW9cqXqrhwYGUxsfZl8fLG8WpJ8iavBt/RHjiox4kl/YeTgMfJ1u7OmOEM1TuT8+8uXcfng3ERv0iKcKDw3Gc051iceoJsA5deLy8AVDiG3prtftcb5GKQjRLNm43mtQZQyh7p30OHhw83y9f5sFxdlD6I/0bDH95bn5v4jEiGqK2xIbezzyHsNH1Iht4N/5of3oG+xou9wXmBikv+BzkRSLL6QIT8AHPd/2nnymvD2sIfFAqbIkN2U9nP86+XB8M51k/4QwQBzjOI6CL7R6agqvQydFKa8FBNgKhCoSK6CDP+le6RpDohN+w2n3+k5IH53Hpf5//v2f+orQYzApM3t7EYyiA3WiS3Ah6Cj4sQnSS95YcXe0+3yeDS3v26fB0pwj9AVu5yAYWWB8GjOgd4KhWq+S9umCBnwIc55sIjT685iAJnR2UFtmA+cvEeeT5cHo7PHk0/xpARHIMoiKaSMvy3gZInWztwheBYTqaf312UCrPzSMf81YZJ1tAXW8OjwFJq90j0EMkYHSKlgAHRLvWO/rh2QsoDFDWGSOj03z9CHA0RAaiPl6345QDwhzzlwlkEdBgf3oGFmdLjhakB+SIvLl3f4H1IQP79eQzb1mOlzeALcCIcnRIZ63/9LMryDqafw2rgeQ9snYEDt52fJx9iaTcStef22ZAz8nW7h/p38ifJW+aoMwXBDi+AxwnW7trvaP/nk5jW3U3msQGPbKlpBsQIwAfq90jyGfDeeRD3NOdIrZY13pH0Zi+l9jQ3sNpl1mBTUGEtT4Ypu5gVnhwII3Lb/I5jgNnlpQQCkjf8YDgywIc3wEOx3GOlzd2/jkF+40NDhzCQDAJxXC8vEGOIeU/dMbwoU2v053igZY9fJWH2MhB2Q5PHi9vHC9v8GrGcZz96Rnsl7r2/TEM/oQR8ut51s8n4NELnRYAOIgmjwkqC3B8HzjA0y/lI9iR7fAkkpLb4Uk4d+uDYRz9QvgAQRannnycfflx9iXvRnycfbnaPYKTR1AeyPSvD4ZxPIziEXSKdDvlNGnbHX4DXGPYGpgVPh2CPb/V7hHSNy6aBAi+IMBxFXCAs2u9owgX4eJhIwY7IEhU4JQXv3zxIL6RC1lgfchzIxVbnHqSZ/3Yjqd4BO0hcmCOP4NDTiUd8KEdWjJMON/FH0IDTZwL4QHBlwU4rgiOL+WjPOvHGY5/T6e3w5PmLxNQ2m/u3dcZ25+eQbCaZ/0Ia39/8CtJy3GcD89e7D2ctp/OItmAvUDyZPmUGgR5+CpP1mqB9dHZn91oEvX0yNlBKc/6+b17Age/+QwryedneWTUohDDuNZv744J0pJyzfnyP+uGsuAO9t95YZMIV7pGyLGAPidlwB8c+fDsxVtlHHs6a72jyNvSPirtnZIw4Elg8DihiFtQNq6kakF6QLtCaIYw2GVWTrZ2V7vPjzfX5YnQHFfUHHALSHIo4CjQ5vAYjvy/G390NP8aeygIjCmGpOMdi2wAOyzmLxNfykd0zmiJDbmQR9kLOLm0x1uem4ejusgGyIThKDU/PDik/LEEpFwFOJohoO6iQWUjzVGtVnE2h+c+HdRbYH17E49PtnbJamBp5lk/72PScd+3yjiBBiKsPYGG5Aqf7YaycRyHjgTzsSsOsmB49tPZvYnHdKyVHzMfddfyQWiOZrhpBI7j5Q2cKwajj5c3sHuCnfH96Rk+YkQcAc1BK9txnC/lo9//8SvVfJx9iccRufAipDKiVkgRWfZqtYqMLVyEN/fuw3Dg3BCdXIfNchmay2gOcnJpDNda6ASfA+mv9cEwXi6iczfYe3Oxb30wjINeZAjQAOnztd5RuB3YxsOma0F6sPdwmtQJEXR5Uee5sgsVBTy5FvrexOMv5SNKnSFDyqMWWqe5Q0r7+zSGay3cenBQ+IfNLZ0xnP9DMvTryefz1zAvzlKc7hTLc/N0MMCVlcKuLBxJ+LCnO8XTnSK28l1nSCESHIsn/Y9EO96iIMtFPi/OdlDSBR3xnrLjODQXoskXoJxcubgOAQdOgmEf8mrfrgPGH2df4igoVjmyVdhNhVnBnjsd6syz/gXWh0rs5ZLk8EoLzj8vsL7N4TEokvLc/OlOEQfZyeKQPN6NP0LXOJhClFFAdoQ21eAd03kivLHicnIB0EbMwZkjF55oMNdR8E5zFKeevFXGkeq+2rfrlC+8RbzCdPgqz4eF1WrVfjq7Pz3zfuY5sqU41Uz94jwz/0h5bn79p5/5BvAZUVP3fSqKftERTh7hEBCOT2+HJ6mL050iXsZBEhbbyC6JnmdZuDHQYKiwJUddeHJRaO1P78DR2nELah5wQIDDAybf1i4EOG6r5DwYtwCHB0y+rV0IcNxWyXkwbgEOD5h8W7sQ4LitkvNg3AIcHjD5tnYhwHFbJefBuAU4PGDybe1CgOO2Ss6DcQtweMDk29qFAMdtlZwH4xbg8IDJt7ULAY7bKjkPxi3A4QGTb2sXAhy3VXIejFuAwwMm39YuBDhuq+Q8GLcAhwdMvq1dCHDcVsl5MG7vwGEYhi6uH+ZAqeT+vz7XhxLvwBEMBhljPeL6AQ4wxsQ/HW7Ff+ftUBrXpydqKXunOWr7FjU3nAMCHDdcQO0cngBHO7l/w/sW4LjhAmrn8AQ42sn9G963AMcNF1A7h3eDwIHY03Ec0zRzuZxt24VCQdM0iknbyac72feNAAfQUCqVNE1zHMcwDEVRqtWqpmnpdNpxnEQioarqnRRQOyfdfnBYlqWqaiaTKRQKuq6rqloulw3DAEpKpZJlWcFg0DTNUqmUyWS8TBG2UzI3oO92gsMwDGAim82qqmqaZrVaLRQKLrbYtq3rerVaVVU1nU5bluU4TqVScTUTP1vOgXaCI51OBwKBysUFkdP0qtVqpVJx/Q1Xy7Ky2Wy1Wo3H45lMxrZtai8K18GBdoLDtu1sNsvPKpvNxuNxWZZ9F5ckSaFQKJlMmqZJzWCGYrGYC0/UQBRaxYE2gMOyLJdKcBwnk8kEAgHW+FIUBY4IZm6aZqFQgLvaKl4IOi4OeA2ORCLBGIM1wVBs25ZluTEq/nInmfz2f2Udx9E0LRgMunSPa3ri549wwGtwkKhhFEzT9Pl8VNmoEIlETNMMhUKMsUgkgglXKpVUKmVeXD/CAvFsIw54DY5cLqcoSir17T93SpLUCBB8PfmeqqoyxhRFcRwHyTFVVXlz02ieov4KHPAaHPwQy+VypVKJxWI8DmrLmUyGf8qyLEmSAK9yuQznQzinPItaVfYOHC4nNJfLSZJEya5GKiQYDGKqiqLIskwnKDVNQxluaSaTqYsPy7IMw6CnoG8K3GWaZvOUCcBHT5AOcwmgUqnoul6bpEFKhh5HgQ++iI5pmoZh1A7GMAxN07CfQI29KXgHjkwmAxcBE4tEIlASiUQCNclkslZtQOTZbBa3fD4fUuwQM7KosVgM+Y9alqEXPqgpFAquXnw+n0s58XRqURuLxVxAdxyHplNXuq4eGWPI+fId9fT0MMZ4/9q2bRy8pcdjsVi5XOafutayd+DABgpURaVSoQkjeMFiMk2TZwdsh6sxY4xcFrAGa45XD8Qy2Cxe9qZpomv54iLZ67pOT/EFv9/PGPP7/YqiULAdi8X4NqVSiabD94U2hmHgbiAQgP7Dz56eHh5JGAkPDgRxgUAgHo8rioKn6k6TH0wLy56Cg3ih6zpxkwq0vtPpNM6pY57EF2rJGOM1s2EY2Wy2rllpBI6enh5iItrIskw1fAGAIOjAI2aM8UKCzkPYJUkS/zh0G0ZOIzRNs1ZPAIXUES0JMlWGYVDZ1cU1/fQOHLquJxIJaA5iMS9vxpgsy+AgMQJAcTVjjPGbtKqqappWl3GXAYemadANdVkMmVFAVK1WMRgenZC0aZrAsWtrkDQHb4yAJDKRjuO4wEEdybKsqioBq+4gr6nSO3AYhoHdNeRDa+VNNaRCaPXQLSq4BGBZFqklnlNNwGGapmVZuVwOUnFZCiICzQGH1zRN+BY9PT0kaWALj+dyOUCcHuc1B6JuXdcxKsYY7966wOE4DnlamLUsy6RXePrXV/YIHNhIo2lkMhkSc90CKW3btsnXo5YUwqAZdBKvS6ijRuAgUihIkkQ90rMokJ/BP8ILCQ3i8biu6zQvfqGT5uApSJLEq41azYHeLctKpVK8H0Y6zDXO6/jpEThs204kEtlsFjJoZFbAPjhliUSCVEg2myUhUbCQzWahP3RdT6fTtZ6g4zhNwOG/uGRZTqVSjZDhOA76lSTJ7/fDN+TFUxv7YArxeJykReCIRCKkM2pHW6s5iML5P5KybSSIecp8g+soewSOSqXCR5vEL34xoQzHkJgeiUQoeONtRy6Xc3n7dbnTCBy8Xaj7IFUCHHwQQbcogg0Gg4n/XCR+sjs0WRg+7C75/X5qAIIucFQqFUVRgsEgYREalCJ/fhjXVPYIHI7j4BQg+QqNtlQABf6uz+dTVZVcCtu24aUiid6cL1htfOhLsGv+IN2tDSvoFkXFvOvgOA6CUtojhCPCGCOXGQ0CgQCPD15r4iBt7cpxhWk0kmsqeAcO1w5Z3ZQX7AgtPhd3AhcXVRKvm7AmmUwGg0HeuuPQoSzLvGCaUIhEIsFgkDDNt1RVFYaGr4QjGQwGQ6EQ6pG8CQaD5IigRpIknmwoFHJ1ZFlWMpkkexoKhUiLuHq8pp/egQN+u6ZpCALL5TKJGQWfz+c4Tt0UiKslRQQ4O5jNZsn0XBOb6pJtDq/md0HwMm1oi7HuGK610jtw4Hgf7+e73FKcIa3FQd0arEJKTfK64Vr5daeIewcOYqt6ceEnWRDkCfiYrS4mUAn3sFQqVatV0zQTiYTL6lNfovAjHPAaHNlsVlEU3l2AE14ul1OpVBNA0C0KHAqFgiRJPKkfYYR4tpYDXoMD77HZts3nrAzDqOufEiBQCAQC5JEVCoVKpaJpmpehXS37OrvGa3CAm5lMRpZl3lEwDCMej/MRLI+MQCDAZ40QylI40NkSauPs2gAOHO9LJBLYaud3sHBkJpPJxOPxSCSCtyBJW9C7TNh0CIVCwtW4Vui0ARw0H9u2k8kkZbeovlGhUqn4/X7kjw3DaEv42mhsHVnfTnDw6XC8LR2Px4EVy7Jov8MwjFgslslkaBeb1yUdKZUbMql2goNngWVZcDgKhYJhGPxxQOyJI3mqquolE0c8cVG+GgduCjhKpVL64kLSkzFGHmilUqHt2atNUjx1NQ7cFHDwo7dt2zAM3lHl74qyZxy4ieDwbPKio+YcEOBozp87fVeA406Lv/nk/x/UioW2fYBvbQAAAABJRU5ErkJggg==\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><strong><font color=\"green\">IA 717: Linguistic Differences of Human-Human and AI-Generated Conversations</font></strong></center></h1>\n",
    "<h3><center><font color=\"blue\"><strong>Student Version</strong></font></center></h3>\n",
    "\n",
    "<center>\n",
    "<h3> Project Supervisor <br/> <a>Yi YU</a></h3>\n",
    "<email>yi.yu@inria.fr</email>\n",
    "<br/>\n",
    "\n",
    "Year 2025-2026\n",
    "</center>\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**Context & Objectives**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The application of large language models (LLMs) in dialogue-based scenarios has become part of daily life since 2023. Human-LLM corpora are now available and enable the study on differences between Human-Human conversations and those generated by LLMs. The differences between these conversations can provide insights into potential alignment direction for current LLM-based chatbot with human expectations.\n",
    "\n",
    "The objective of this project is to study the linguistic difference between two chosen corpora, <a href=\"https://github.com/facebookresearch/EmpatheticDialogues\">EmpathicDialogues</a> and <a href=\"https://github.com/morganlee123/2GPTEmpathicDialogues\">2GPTEmpathicDialogues</a>. The second is created as a replica of the first one by prompting two independent instances of ChatGPT. \n",
    "\n",
    "The following image provides an example of two conversations genereated under the same scenario, one by human, the other by ChatGPT.\n",
    "![image.png](https://github.com/morganlee123/2GPTEmpathicDialogues/blob/main/paperfigures/exampledialogue.png?raw=true) \n",
    "\n",
    "We will first start with an exploration of basic concepts for conversation analysis (e.g. nb of turns per conversation, avg words per turn, etc.) and understand what has been studied within these two corpora in <a href=\"https://arxiv.org/abs/2401.16587\">this paper</a>. We will then compare these two corpora on our own, focusing on one linguistic feature for affect study introduced later and calculate it for each conversation.\n",
    "\n",
    "1) explore the mentioned corpora\n",
    "2) analyze the general information about each corpus: the size of corpus and the setting used for the corpus creation \n",
    "3) study one linguistic feature for collaborative state analysis, <a href=\"https://www.liwc.app/help/lsm\">language style matching</a>, calculate it for each pair of participants, human or ChatGPT, and finally compare the level of matching between two corpora\n",
    "4) build a baseline model for LLM-generated dialogue detection using only word embedding as feature\n",
    "5) add the calculated feature from step <a>3</a> to your baseline model to see if there is any improvement in performance\n",
    "6) highlight your findings during the experiment\n",
    "\n",
    "\n",
    "### <font color=\"green\">Evaluation</font>\n",
    "\n",
    "The project is evaluated through a presentation with a report and your completed project. Grades will be partly individual and partly collective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**1 & 2 - Data Retrieval & Analysis**</font>\n",
    "\n",
    "We need to download the two mentioned corpora using the link provided earlier. Each conversation in EmpatheticDialogue should be paired with a conversation in 2GPTEmpathicDialogues. Check if any conversation cannot be paired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1.1 Question: </font>  \n",
    "Preprocessing and Data Exploration â€” Answer the following:\n",
    "\n",
    "- How many conversations in EmpatheticDialogue can be paired with those in 2GPTEmpathicDialogues?  \n",
    "- What is the average number of turns per conversation in each corpus?  \n",
    "- What is the average number of words per conversation in both corpora?  \n",
    "- How are conversations distributed across different emotional contexts (e.g., annoyed, proud, furious)?  \n",
    "\n",
    "Present your findings using appropriate graphs and visualizations where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">1.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_test = pd.read_csv('../data/empatheticdialogues/test.csv', quoting=3, usecols=[0,1,2,3,4,5,6])\n",
    "human_valid = pd.read_csv('../data/empatheticdialogues/valid.csv', quoting=3, usecols=[0,1,2,3,4,5,6])\n",
    "human_train = pd.read_csv('../data/empatheticdialogues/train.csv', quoting=3, usecols=[0,1,2,3,4,5,6])\n",
    "gpt = pd.read_csv('../data/gptempatheticdialogues/2GPTEmpathicDialoguesDataset.csv')\n",
    "human = pd.concat([human_test, human_valid, human_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt['utterance'] = gpt['processed'].str.split('\\n')\n",
    "gpt_exploded = gpt.explode('utterance')\n",
    "gpt_exploded = gpt_exploded[gpt_exploded['utterance'] != '']\n",
    "gpt_exploded['utterance_idx'] = gpt_exploded.groupby('conv_id').cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107220, 7), (160885, 8))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.shape, gpt_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_human_conv_id = human[['conv_id']].drop_duplicates()\n",
    "unique_gpt_conv_id = gpt_exploded[['conv_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185765, 13)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.merge(gpt_exploded, human, on=['conv_id', 'utterance_idx'], how='outer')\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_gpt_conv_id['present_in_human'] = unique_gpt_conv_id['conv_id'].isin(unique_human_conv_id['conv_id'])\n",
    "present_gpt_absent_human = unique_gpt_conv_id[~unique_gpt_conv_id['present_in_human']]\n",
    "\n",
    "unique_human_conv_id['present_in_gpt'] = unique_human_conv_id['conv_id'].isin(unique_gpt_conv_id['conv_id'])\n",
    "present_human_absent_gpt = unique_human_conv_id[~unique_human_conv_id['present_in_gpt']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_conv_id_1 = unique_human_conv_id[unique_human_conv_id['present_in_gpt']]\n",
    "common_conv_id_2 = unique_gpt_conv_id[unique_gpt_conv_id['present_in_human']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19533, 2), (19533, 2))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_conv_id_1.shape, common_conv_id_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5317, 2), (0, 2))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_human_absent_gpt.shape, present_gpt_absent_human.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 19533 conversations are shared, with 5317 conversation missing from the gpt dataset\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4.3146881287726355), np.float64(8.236574002969334))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_per_conv_human = human.groupby('conv_id')['conv_id'].count().mean()\n",
    "turns_per_conv_gpt = gpt_exploded.groupby('conv_id')['conv_id'].count().mean()\n",
    "\n",
    "turns_per_conv_human, turns_per_conv_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 4.31 for human, 8.23 for gpt\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(67.05971830985915), np.float64(351.66395330978344))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human['word_length'] = human['utterance'].apply(lambda utt: len(tokenize.word_tokenize(utt)))\n",
    "words_per_conv_human = human.groupby('conv_id')['word_length'].sum().mean()\n",
    "gpt_exploded['word_length'] = gpt_exploded['utterance'].apply(lambda utt: len(tokenize.word_tokenize(utt)))\n",
    "words_per_conv_gpt = gpt_exploded.groupby('conv_id')['word_length'].sum().mean()\n",
    "\n",
    "words_per_conv_human, words_per_conv_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 67 for human and 351 for gpt\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afraid</th>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "      <td>3441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "      <td>3708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyed</th>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anticipating</th>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxious</th>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apprehensive</th>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ashamed</th>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "      <td>2956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confident</th>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "      <td>3393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devastated</th>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointed</th>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "      <td>3324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusted</th>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "      <td>3387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassed</th>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "      <td>3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excited</th>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "      <td>4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faithful</th>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furious</th>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grateful</th>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "      <td>3489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilty</th>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopeful</th>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressed</th>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "      <td>3415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jealous</th>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "      <td>3284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joyful</th>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "      <td>3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lonely</th>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "      <td>3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nostalgic</th>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "      <td>3274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared</th>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "      <td>3273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proud</th>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "      <td>3701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentimental</th>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "      <td>3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprised</th>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "      <td>5508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terrified</th>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trusting</th>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "      <td>2875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              conv_id  utterance_idx  prompt  speaker_idx  utterance  \\\n",
       "context                                                                \n",
       "afraid           3441           3441    3441         3441       3441   \n",
       "angry            3708           3708    3708         3708       3708   \n",
       "annoyed          3790           3790    3790         3790       3790   \n",
       "anticipating     3281           3281    3281         3281       3281   \n",
       "anxious          3334           3334    3334         3334       3334   \n",
       "apprehensive     2654           2654    2654         2654       2654   \n",
       "ashamed          2785           2785    2785         2785       2785   \n",
       "caring           2956           2956    2956         2956       2956   \n",
       "confident        3393           3393    3393         3393       3393   \n",
       "content          3191           3191    3191         3191       3191   \n",
       "devastated       3047           3047    3047         3047       3047   \n",
       "disappointed     3324           3324    3324         3324       3324   \n",
       "disgusted        3387           3387    3387         3387       3387   \n",
       "embarrassed      3165           3165    3165         3165       3165   \n",
       "excited          4034           4034    4034         4034       4034   \n",
       "faithful         2101           2101    2101         2101       2101   \n",
       "furious          3294           3294    3294         3294       3294   \n",
       "grateful         3489           3489    3489         3489       3489   \n",
       "guilty           3270           3270    3270         3270       3270   \n",
       "hopeful          3340           3340    3340         3340       3340   \n",
       "impressed        3415           3415    3415         3415       3415   \n",
       "jealous          3284           3284    3284         3284       3284   \n",
       "joyful           3280           3280    3280         3280       3280   \n",
       "lonely           3498           3498    3498         3498       3498   \n",
       "nostalgic        3274           3274    3274         3274       3274   \n",
       "prepared         3273           3273    3273         3273       3273   \n",
       "proud            3714           3714    3714         3714       3714   \n",
       "sad              3701           3701    3701         3701       3701   \n",
       "sentimental      3047           3047    3047         3047       3047   \n",
       "surprised        5508           5508    5508         5508       5508   \n",
       "terrified        3367           3367    3367         3367       3367   \n",
       "trusting         2875           2875    2875         2875       2875   \n",
       "\n",
       "              selfeval  word_length  \n",
       "context                              \n",
       "afraid            3441         3441  \n",
       "angry             3708         3708  \n",
       "annoyed           3790         3790  \n",
       "anticipating      3281         3281  \n",
       "anxious           3334         3334  \n",
       "apprehensive      2654         2654  \n",
       "ashamed           2785         2785  \n",
       "caring            2956         2956  \n",
       "confident         3393         3393  \n",
       "content           3191         3191  \n",
       "devastated        3047         3047  \n",
       "disappointed      3324         3324  \n",
       "disgusted         3387         3387  \n",
       "embarrassed       3165         3165  \n",
       "excited           4034         4034  \n",
       "faithful          2101         2101  \n",
       "furious           3294         3294  \n",
       "grateful          3489         3489  \n",
       "guilty            3270         3270  \n",
       "hopeful           3340         3340  \n",
       "impressed         3415         3415  \n",
       "jealous           3284         3284  \n",
       "joyful            3280         3280  \n",
       "lonely            3498         3498  \n",
       "nostalgic         3274         3274  \n",
       "prepared          3273         3273  \n",
       "proud             3714         3714  \n",
       "sad               3701         3701  \n",
       "sentimental       3047         3047  \n",
       "surprised         5508         5508  \n",
       "terrified         3367         3367  \n",
       "trusting          2875         2875  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "contexts_human = human.drop_duplicates('conv_id').groupby('context')['conv_id'].count()\n",
    "contexts_human\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conv_id</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gptgen</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_split</th>\n",
       "      <th>utterance_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>hit:10015_conv:20031</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My little child is dancing now. I'm amazing ab...</td>\n",
       "      <td>assistant1: Listener: Look at my little child,...</td>\n",
       "      <td>look at my little child, she's dancing now!\\...</td>\n",
       "      <td>look at my little child, she's dancing now!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>hit:10015_conv:20031</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My little child is dancing now. I'm amazing ab...</td>\n",
       "      <td>assistant1: Listener: Look at my little child,...</td>\n",
       "      <td>look at my little child, she's dancing now!\\...</td>\n",
       "      <td>wow, that's incredible! your little child has...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>hit:10015_conv:20031</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My little child is dancing now. I'm amazing ab...</td>\n",
       "      <td>assistant1: Listener: Look at my little child,...</td>\n",
       "      <td>look at my little child, she's dancing now!\\...</td>\n",
       "      <td>it's truly heartwarming to see your little c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>hit:10015_conv:20031</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My little child is dancing now. I'm amazing ab...</td>\n",
       "      <td>assistant1: Listener: Look at my little child,...</td>\n",
       "      <td>look at my little child, she's dancing now!\\...</td>\n",
       "      <td>thank you so much! i am beyond proud of her....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>hit:10015_conv:20031</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My little child is dancing now. I'm amazing ab...</td>\n",
       "      <td>assistant1: Listener: Look at my little child,...</td>\n",
       "      <td>look at my little child, she's dancing now!\\...</td>\n",
       "      <td>i can see why you're so proud. it's truly he...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               conv_id    context  \\\n",
       "27          27  hit:10015_conv:20031  impressed   \n",
       "27          27  hit:10015_conv:20031  impressed   \n",
       "27          27  hit:10015_conv:20031  impressed   \n",
       "27          27  hit:10015_conv:20031  impressed   \n",
       "27          27  hit:10015_conv:20031  impressed   \n",
       "\n",
       "                                               prompt  \\\n",
       "27  My little child is dancing now. I'm amazing ab...   \n",
       "27  My little child is dancing now. I'm amazing ab...   \n",
       "27  My little child is dancing now. I'm amazing ab...   \n",
       "27  My little child is dancing now. I'm amazing ab...   \n",
       "27  My little child is dancing now. I'm amazing ab...   \n",
       "\n",
       "                                               gptgen  \\\n",
       "27  assistant1: Listener: Look at my little child,...   \n",
       "27  assistant1: Listener: Look at my little child,...   \n",
       "27  assistant1: Listener: Look at my little child,...   \n",
       "27  assistant1: Listener: Look at my little child,...   \n",
       "27  assistant1: Listener: Look at my little child,...   \n",
       "\n",
       "                                            processed  \\\n",
       "27    look at my little child, she's dancing now!\\...   \n",
       "27    look at my little child, she's dancing now!\\...   \n",
       "27    look at my little child, she's dancing now!\\...   \n",
       "27    look at my little child, she's dancing now!\\...   \n",
       "27    look at my little child, she's dancing now!\\...   \n",
       "\n",
       "                                      processed_split  utterance_idx  \n",
       "27        look at my little child, she's dancing now!              1  \n",
       "27   wow, that's incredible! your little child has...              2  \n",
       "27    it's truly heartwarming to see your little c...              3  \n",
       "27    thank you so much! i am beyond proud of her....              4  \n",
       "27    i can see why you're so proud. it's truly he...              5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">1.2 Question:</font> Summarize your findings during the preprocessing process. Do you think we should include all the available contexts for our study? Why? 'Context' here refer to a column name in EmpatheticDialogue csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<font color=\"orange\">1.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">2.1 Question:</font> Understand the prompting design used in 2GPTEmpathicDialogue generation. What are the advantages and limitations of this setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">2.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**3 - Linguistic Feature for the Affective State between Participants**</font>\n",
    "\n",
    "LSM is a linguistic feature related to affect analysis. You can add more as you like. You need to make sure each of your choice is supported by at least one published paper since the references are required. You need to check how to calculate each of the feature using dialogue text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.0 Question:</font> What is the affect analysis? What are possible scenario/application for affect analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.0 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.1 Question:</font> How can the selected linguistic features be implemented for affective state analysis? If you use any open-source libraries or tools, please specify them and reference them in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.2 Question:</font> Is affective state impacted by scenario setting? What are the scenario that achieve highest affective state between human participants? Does ChatGPT generated conversation share the same answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.3 Question:</font> What are scenarios selected for this project? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**4 - Modeling for ChatGPT-Generated Dialogue Detection**</font>\n",
    "\n",
    "Our first baseline model can be defined since two corpora provide naturally labeled conversations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.1 Question:</font> Which word embedding model is used by the paper? Why? Which word embedding model will you use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test several word embedding model and choos the one give you the best performance GPT generated dialogue classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.2 Question:</font> How to define the binary classification task? Test both linear and non-linear models to see which model provide better performance? You can follow the test, train, valid seperation defined inside Empatheticdiaogues corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.3 Question:</font> What metrics do you use to evaluate your model's performance? What is the performance of your baseline model? In which scenario does your model achieve the best performance?Present the performance using appropriate graphs and visualizations where possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">5 - Add Selected Features to Your Baseline Model</font>\n",
    "\n",
    "Add calculated features into your baseline model. What is the performance if we use only the linguistic feature for our classification task? How to encode the features and add them to the existing word embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.1 Question:</font> Let's build a linear classifier using only the linguistic feature LSM. What are your best performance?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the tested linear classifier and their performance. Highlight the scenario that give best performance for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.2 Question:</font> Try adding LSM to your baseline model. What is the nature of the calculated features (scaled, categorical, etc.)? How do you add them to the existing word embedding vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.3 Question:</font> After adding LSM to your baseline model, are there any changes in the model's performance? How do you interpret the result? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**6 - Highlight Your Findings**</font>\n",
    "This is an open question. Anything that stands out in your analysis should be highlighted. It could be a significant trend, an anomaly, or a correlation that was unexpected. Use visual aids like graphs or charts to make these findings clear and impactful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
