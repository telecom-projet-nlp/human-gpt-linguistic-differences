{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"data:image/png;base64,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\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><strong><font color=\"green\">IA 717: Linguistic Differences of Human-Human and AI-Generated Conversations</font></strong></center></h1>\n",
    "<h3><center><font color=\"blue\"><strong>Student Version</strong></font></center></h3>\n",
    "\n",
    "<center>\n",
    "<h3> Project Supervisor <br/> <a>Yi YU</a></h3>\n",
    "<email>yi.yu@inria.fr</email>\n",
    "<br/>\n",
    "\n",
    "Year 2025-2026\n",
    "</center>\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**Context & Objectives**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The application of large language models (LLMs) in dialogue-based scenarios has become part of daily life since 2023. Human-LLM corpora are now available and enable the study on differences between Human-Human conversations and those generated by LLMs. The differences between these conversations can provide insights into potential alignment direction for current LLM-based chatbot with human expectations.\n",
    "\n",
    "The objective of this project is to study the linguistic difference between two chosen corpora, <a href=\"https://github.com/facebookresearch/EmpatheticDialogues\">EmpathicDialogues</a> and <a href=\"https://github.com/morganlee123/2GPTEmpathicDialogues\">2GPTEmpathicDialogues</a>. The second is created as a replica of the first one by prompting two independent instances of ChatGPT. \n",
    "\n",
    "The following image provides an example of two conversations genereated under the same scenario, one by human, the other by ChatGPT.\n",
    "![image.png](https://github.com/morganlee123/2GPTEmpathicDialogues/blob/main/paperfigures/exampledialogue.png?raw=true) \n",
    "\n",
    "We will first start with an exploration of basic concepts for conversation analysis (e.g. nb of turns per conversation, avg words per turn, etc.) and understand what has been studied within these two corpora in <a href=\"https://arxiv.org/abs/2401.16587\">this paper</a>. We will then compare these two corpora on our own, focusing on one linguistic feature for affect study introduced later and calculate it for each conversation.\n",
    "\n",
    "1) explore the mentioned corpora\n",
    "2) analyze the general information about each corpus: the size of corpus and the setting used for the corpus creation \n",
    "3) study one linguistic feature for collaborative state analysis, <a href=\"https://www.liwc.app/help/lsm\">language style matching</a>, calculate it for each pair of participants, human or ChatGPT, and finally compare the level of matching between two corpora\n",
    "4) build a baseline model for LLM-generated dialogue detection using only word embedding as feature\n",
    "5) add the calculated feature from step <a>3</a> to your baseline model to see if there is any improvement in performance\n",
    "6) highlight your findings during the experiment\n",
    "\n",
    "\n",
    "### <font color=\"green\">Evaluation</font>\n",
    "\n",
    "The project is evaluated through a presentation with a report and your completed project. Grades will be partly individual and partly collective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**1 & 2 - Data Retrieval & Analysis**</font>\n",
    "\n",
    "We need to download the two mentioned corpora using the link provided earlier. Each conversation in EmpatheticDialogue should be paired with a conversation in 2GPTEmpathicDialogues. Check if any conversation cannot be paired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1.1 Question: </font>  \n",
    "Preprocessing and Data Exploration — Answer the following:\n",
    "\n",
    "- How many conversations in EmpatheticDialogue can be paired with those in 2GPTEmpathicDialogues?  \n",
    "- What is the average number of turns per conversation in each corpus?  \n",
    "- What is the average number of words per conversation in both corpora?  \n",
    "- How are conversations distributed across different emotional contexts (e.g., annoyed, proud, furious)?  \n",
    "\n",
    "Present your findings using appropriate graphs and visualizations where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">1.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dial_gpt = pd.read_csv(\"/Users/andrew/MS IA/NLP/human-gpt-linguistic-differences/data/2GPTEmpathicDialoguesDataset.csv\")\n",
    "dial_human = pd.read_csv(\"/Users/andrew/MS IA/NLP/human-gpt-linguistic-differences/data/empatheticdialogues/train.csv\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84169 entries, 0 to 84168\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   conv_id        84169 non-null  object\n",
      " 1   utterance_idx  84169 non-null  int64 \n",
      " 2   context        84169 non-null  object\n",
      " 3   prompt         84169 non-null  object\n",
      " 4   speaker_idx    84169 non-null  int64 \n",
      " 5   utterance      84169 non-null  object\n",
      " 6   selfeval       84169 non-null  object\n",
      " 7   tags           755 non-null    object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 5.1+ MB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19533 entries, 0 to 19532\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  19533 non-null  int64 \n",
      " 1   conv_id     19533 non-null  object\n",
      " 2   context     19533 non-null  object\n",
      " 3   prompt      19533 non-null  object\n",
      " 4   gptgen      19533 non-null  object\n",
      " 5   processed   19533 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 915.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dial_human.info()\n",
    "print(\"\\n\")\n",
    "dial_gpt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">1.2 Question:</font> Summarize your findings during the preprocessing process. Do you think we should include all the available contexts for our study? Why? 'Context' here refer to a column name in EmpatheticDialogue csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<font color=\"orange\">1.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">2.1 Question:</font> Understand the prompting design used in 2GPTEmpathicDialogue generation. What are the advantages and limitations of this setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">2.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**3 - Linguistic Feature for the Affective State between Participants**</font>\n",
    "\n",
    "LSM is a linguistic feature related to affect analysis. You can add more as you like. You need to make sure each of your choice is supported by at least one published paper since the references are required. You need to check how to calculate each of the feature using dialogue text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.0 Question:</font> What is the affect analysis? What are possible scenario/application for affect analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.0 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.1 Question:</font> How can the selected linguistic features be implemented for affective state analysis? If you use any open-source libraries or tools, please specify them and reference them in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.2 Question:</font> Is affective state impacted by scenario setting? What are the scenario that achieve highest affective state between human participants? Does ChatGPT generated conversation share the same answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">3.3 Question:</font> What are scenarios selected for this project? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">3.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**4 - Modeling for ChatGPT-Generated Dialogue Detection**</font>\n",
    "\n",
    "Our first baseline model can be defined since two corpora provide naturally labeled conversations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.1 Question:</font> Which word embedding model is used by the paper? Why? Which word embedding model will you use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test several word embedding model and choos the one give you the best performance GPT generated dialogue classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.2 Question:</font> How to define the binary classification task? Test both linear and non-linear models to see which model provide better performance? You can follow the test, train, valid seperation defined inside Empatheticdiaogues corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">4.3 Question:</font> What metrics do you use to evaluate your model's performance? What is the performance of your baseline model? In which scenario does your model achieve the best performance?Present the performance using appropriate graphs and visualizations where possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">4.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">5 - Add Selected Features to Your Baseline Model</font>\n",
    "\n",
    "Add calculated features into your baseline model. What is the performance if we use only the linguistic feature for our classification task? How to encode the features and add them to the existing word embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.1 Question:</font> Let's build a linear classifier using only the linguistic feature LSM. What are your best performance?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the tested linear classifier and their performance. Highlight the scenario that give best performance for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.1 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.2 Question:</font> Try adding LSM to your baseline model. What is the nature of the calculated features (scaled, categorical, etc.)? How do you add them to the existing word embedding vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.2 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">5.3 Question:</font> After adding LSM to your baseline model, are there any changes in the model's performance? How do you interpret the result? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">5.3 Answer:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\">**6 - Highlight Your Findings**</font>\n",
    "This is an open question. Anything that stands out in your analysis should be highlighted. It could be a significant trend, an anomaly, or a correlation that was unexpected. Use visual aids like graphs or charts to make these findings clear and impactful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
